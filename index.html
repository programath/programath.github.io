<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Structure" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/28/Structure/" class="article-date">
  <time datetime="2017-08-28T05:58:41.000Z" itemprop="datePublished">2017-08-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/28/Structure/">Is Relu Useful in Network Quantization?</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Relu is a widely used non-linear activation function in Recently Neural Network. Relu is not a neccesary layer after doing convolution operation, but it forces those negetive values of feature map to be zero, results in the sparity of feature map<br>and keeps all activation to become non-negative.<br>Intuitively, in quantization task, relu reduces the quantization range, which allows low bit to express numbers more accurately. But can relu always benifit the quantization of CNN?</p>
<p>Maybe it is useful in many network structures, and in fact I have benefitted from it in quantizing vgg-like Network. But is not for some special cases. Let’s assume a structure, a 3x3 convolution followed by a 1x1 convolution, which<br>is commonly used in ResNet and so on. There is a special property of 1x1 convolution that it doesn’t expand the receptive field of feature map, which we can easily merge the 1x1 convolution into 3x3 convolution, if there is no relu layer inserted between them.</p>
<p>Compare this two kind of structure, one is 3x3, $$i$$ input channels and $$t$$ output channels, followed by 1x1, $$t$$ input channels and $$o$$ output channels. Another is a merged version of convolution, with 3x3 kernel size, $$i$$ input channels and $$o$$ output channels. We compare this two kinds of structure by estimating their computation amount, parameter amout.</p>
<ul>
<li>computation amount: 3x3xtxi+1x1xtxo vs. 3x3xixo</li>
<li>parameter amount: 3x3xtxi+1x1xtxo vs. 3x3xixo</li>
</ul>
<p>As we can see, if $$t$$ is larger than $$o$$, there is no doubt that merged version can save computation resources. </p>
<p><strong>GPU Performance</strong><br>We implement the convolution using caffe framework. In caffe, convolution is transformed into a matrix multiplication. It computes the result parallelly on output channel dim.<br>Experiment results show that reducing output channel cannot significantly lower the running time. All we can benefit from the merged version is the removal of 1x1 convolution and time can be saved.</p>
<p><strong>FPGA Performance</strong><br>FPGA cannot completely compute parallelly on out channel dimension. It’s obiviously that reducing the output channel can reduce loop trip count, and it can also reduce cost of data load and save, which is often the bottleneck of FPGA design. But if $$t &lt; o$$, there will be an increase in computation amount, which may unfortunately cost more time.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/28/Structure/" data-id="cj6vu50420002nq4ivw3rhct8" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Network" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/25/Network/" class="article-date">
  <time datetime="2017-08-25T10:56:04.000Z" itemprop="datePublished">2017-08-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/25/Network/">Low-Bit Quantization Strategy of Convolution Neural Network</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>Motivation</strong><br>It has been well shown that quantizing a convolution neural network can significant reduce the overhead of computation on hardware. A hardware friendly quantization strategy involves fixed-point, few multiplication and low bitwise. Many researches have shown that quantizing a full precision CNN into 8bit can achieve little degradtion in accuracy. And another extreme low bit scheme like Binary-Wise Network, Binary Neural Network, XNOR Network also shows that low-bit quantization preform well in some extent. </p>
<p>Since fixed-point quantization and bitwise operation give a opportunity to break the limitation of computation resources such as dsp on FPGA,  the bandwidth becomes the deterministic factor of the computation efficiency. Low bit wise quantization apparently can mitigate the load of bandwidth</p>
<p><strong>activation quantization</strong><br>Efficient bit wise is usuaslly integer power of 2, in order to make good use of the whole bit width of the bus. We consider a 4bit quantization scheme to transfer feature map into computation core. Usual quantization of 4bit is dynamic fixed point quantization. And in tensorflow, they quantize numbers into a linear distribution among the range of activations. In our implement, we try to use the code book and loop-up table on FPGA to quickly quantize activations.</p>
<p>The code book contains 16 numbers when 4bit quantization scheme is utilized. The way to find code book is simply use K-Means to optimize the F-norm function:<br>$$<br>\min||\mathbf{a}-q\mathbf{(a)}||_{F}<br>$$</p>
<p>Although there is a limitation of the range which 4bit codebook can depict, the result shows that the outlier of feature map won’t significantly impact the computation output,<br>except the top fc-layer. Some reseach have shown that in classification task, low bit can still work well. But on segmentation task, each pixel will be taken into consideration<br>independly, unlike classification task, which only needs a single output.  In our experiment, we show that quantizing the fc layer into 4bit codebook before it is fed into softmax layer will cause a 3% reduction on the accuracy.<br>compare to 6bit dynamic fixed-point quantization. So it’s merging softmax layer into fc layer on FPGA that be a more better way to quantize the network into 4bit.</p>
<p><strong>weight quantization</strong><br>Quantizing weight into low bit is not difficult. Many related work like Binary Neural Network, Tenary Neural Network have show impressive performances even when weights are quantized into extreme low bit, and some work show quantize weight into 2-power can also work well, while in my project I cannot reproduce its performance by finefuning the full precision network.<br>To obtain the benefits of 2-power weight, I quantize the weight into the sum of two 2-power number. This strategy will cost 8 bits in my design, but there is no gap to finetune it from a full precision network. The burden of 8 bit weight seems not to do harm to the transfer efficiency because the amount of weight is relatively small.<br>In my experiment, this kind of quantize strategy is nearly lossless in mIOU measurement of segementation task.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/25/Network/" data-id="cj6vu503t0000nq4i5vh29i5x" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-test" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/25/test/" class="article-date">
  <time datetime="2017-08-25T09:06:07.000Z" itemprop="datePublished">2017-08-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/25/test/">test</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="This-a-test-post-of-hexo-blog"><a href="#This-a-test-post-of-hexo-blog" class="headerlink" title="This a test post of hexo blog"></a>This a test post of hexo blog</h1><p>#</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/25/test/" data-id="cj6vu50470004nq4ietuvc63g" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/25/hello-world/" class="article-date">
  <time datetime="2017-08-25T08:44:11.000Z" itemprop="datePublished">2017-08-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/25/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/25/hello-world/" data-id="cj6vu50460003nq4ilgwy0ss9" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/08/28/Structure/">Is Relu Useful in Network Quantization?</a>
          </li>
        
          <li>
            <a href="/2017/08/25/Network/">Low-Bit Quantization Strategy of Convolution Neural Network</a>
          </li>
        
          <li>
            <a href="/2017/08/25/test/">test</a>
          </li>
        
          <li>
            <a href="/2017/08/25/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 John Doe<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>